{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection of Utilities for T-DAB Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220000 entries, 0 to 219999\n",
      "Data columns (total 27 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   CurrentSpeed  219833 non-null  float64\n",
      " 1   CurrentDir    219832 non-null  float64\n",
      " 2   TWS           219837 non-null  float64\n",
      " 3   TWA           219833 non-null  float64\n",
      " 4   AWS           219834 non-null  float64\n",
      " 5   AWA           219838 non-null  float64\n",
      " 6   Roll          219833 non-null  float64\n",
      " 7   Pitch         219836 non-null  float64\n",
      " 8   HeadingMag    219835 non-null  float64\n",
      " 9   HoG           219838 non-null  float64\n",
      " 10  HeadingTrue   219837 non-null  float64\n",
      " 11  AirTemp       219840 non-null  float64\n",
      " 12  Longitude     219836 non-null  float64\n",
      " 13  Latitude      219840 non-null  float64\n",
      " 14  SoG           219842 non-null  float64\n",
      " 15  SoS           219840 non-null  float64\n",
      " 16  AvgSoS        219838 non-null  float64\n",
      " 17  VMG           219837 non-null  float64\n",
      " 18  RudderAng     219838 non-null  float64\n",
      " 19  Leeway        219839 non-null  float64\n",
      " 20  TWD           219838 non-null  float64\n",
      " 21  WSoG          219836 non-null  float64\n",
      " 22  VoltageDrawn  219839 non-null  float64\n",
      " 23  ModePilote    219839 non-null  float64\n",
      " 24  DateTime      219995 non-null  object \n",
      " 25  Yaw           219834 non-null  float64\n",
      " 26  Tacking       219995 non-null  float64\n",
      "dtypes: float64(26), object(1)\n",
      "memory usage: 45.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Importing labeled data \n",
    "df= pd.read_csv('./data/test_data.csv', header = 0)\n",
    "# Check raw data variable information: rows, columns, non-nulls, dtypes\n",
    "df.info()\n",
    "# data_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Values Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check unique values of categorical variables and their respective counts\n",
    "def counting_values(df, var_list, sort = True, verbose = True):\n",
    "    for col in var_list:\n",
    "        try:\n",
    "            series = None\n",
    "            series = df[col]\n",
    "            if verbose:\n",
    "                print(\"Counts for '{}' variable:\".format(col))\n",
    "                if sort:\n",
    "                    print(series.value_counts(dropna = False).sort_index())\n",
    "                    print()\n",
    "                else:\n",
    "                    print(series.value_counts(dropna = False))\n",
    "                    print()\n",
    "        except:\n",
    "            pass\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for 'Leeway' variable:\n",
      "-10.0       121\n",
      "-9.0         22\n",
      "-8.0         25\n",
      "-7.0         25\n",
      "-6.0         37\n",
      "-5.0         86\n",
      "-4.0        688\n",
      "-3.0       6817\n",
      "-2.0      66051\n",
      "-1.0     112020\n",
      " 0.0      33880\n",
      " 1.0         43\n",
      " 2.0         11\n",
      " 3.0          7\n",
      " 4.0          3\n",
      " 5.0          2\n",
      " 9.0          1\n",
      " NaN        161\n",
      "Name: Leeway, dtype: int64\n",
      "\n",
      "Counts for 'ModePilote' variable:\n",
      "2.0    188870\n",
      "5.0     30969\n",
      "NaN       161\n",
      "Name: ModePilote, dtype: int64\n",
      "\n",
      "Counts for 'Tacking' variable:\n",
      "0.0    173956\n",
      "1.0     46039\n",
      "NaN         5\n",
      "Name: Tacking, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select columns to inspect. I.e: those with less than 'x' unique values\n",
    "uniques = 20\n",
    "columns = [col for col in df.columns if len(df[col].unique()) < uniques ]\n",
    "# Call function on our data\n",
    "counting_values(df,columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module for building and plotting PMFs and CDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: empiricaldist in /Users/laureanonisenbaum/opt/anaconda3/lib/python3.7/site-packages (0.3.10)\r\n"
     ]
    }
   ],
   "source": [
    "# Install required packages/modules\n",
    "# https://nbviewer.jupyter.org/github/AllenDowney/empiricaldist/blob/master/empiricaldist/dist_demo.ipynb\n",
    "!pip install empiricaldist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.0    0.000550\n",
       "-9.0     0.000100\n",
       "-8.0     0.000114\n",
       "-7.0     0.000114\n",
       "-6.0     0.000168\n",
       "Name: Leeway, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building empirical distribution from series\n",
    "from empiricaldist import Pmf\n",
    "pmf_leeway = Pmf.from_seq(df['Leeway'], normalize=True)\n",
    "\n",
    "pmf_leeway.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decorate(title):\n",
    "    \"\"\"Labels the axes.\n",
    "    \n",
    "    title: string\n",
    "    \"\"\"\n",
    "    plt.xlabel('Outcome')\n",
    "    plt.ylabel('PMF')\n",
    "    plt.title(title)\n",
    "\n",
    "\n",
    "pmf_leeway.bar()\n",
    "decorate('Leeway')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to test `pd.interpolate()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWS_mask = df['TWS'].isnull()\n",
    "df.iloc[15305:15315]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Plot with Resampling \n",
    "# Some options: '#min' = '#T', 'H', 'D', 'B' (business day), 'W', 'M', 'Q', 'Y'\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15,8)\n",
    "\n",
    "ax = df['AirTemp'].resample('30min').mean().plot(color = 'b')\n",
    "ax.set_title('Temperature over Time')\n",
    "ax.set_xlabel('Time', fontsize = 20)\n",
    "ax.set_ylabel('Temperature [Celcius]', fontsize = 20)\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature plot Slicing by Index\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15,8)\n",
    "\n",
    "ax = df['AirTemp']['2019-04-14 06:00:00':'2019-04-14 07:00:00'].plot(color = 'b')\n",
    "ax.set_title('Temperature over Time')\n",
    "ax.set_xlabel('Time', fontsize = 20)\n",
    "ax.set_ylabel('Temperature [Celcius]', fontsize = 20)\n",
    "\n",
    "# Add a red vertical line\n",
    "ax.axvline('2019-04-14 06:30:00', color='red', linestyle='--')\n",
    "\n",
    "# Add a green horizontal line\n",
    "ax.axhline(30, color='green', linestyle='--')\n",
    "\n",
    "# Add a vertical red shaded region between the dates of 1900-01-01 and 1915-01-01\n",
    "ax.axvspan('2019-04-14 06:10:00','2019-04-14 06:20:00', color='orange', alpha=0.3)\n",
    "\n",
    "# Add a horizontal green shaded region between the values of 6 and 8\n",
    "ax.axhspan(31, 32, color='green', alpha=0.3)\n",
    "\n",
    "\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e37f75efc443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(\"Test set accuracy: {:.2f}\".format(acc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Compute precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "# print(\"Test set accuracy: {:.2f}\".format(acc))\n",
    "\n",
    "# Compute precision\n",
    "pres = precision_score(y_test, y_pred)\n",
    "# print(\"Precision: \\n\",pres)\n",
    "\n",
    "# Compute recall\n",
    "reca = recall_score(y_test, y_pred)\n",
    "# print(\"Recall: \\n\",reca)\n",
    "\n",
    "# Compute f1-score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "# print(\"F1: \\n\",f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!brew install libomp\n",
    "!pip install xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return 'gini', gini_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = 5\n",
    "skf = StratifiedKFold(n_splits=kfold)\n",
    "\n",
    "params = {\n",
    "    'min_child_weight': 10.0,\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 7,\n",
    "    'max_delta_step': 1.8,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'subsample': 0.8,\n",
    "    'eta': 0.025,\n",
    "    'gamma': 0.65,\n",
    "    'num_boost_round' : 700\n",
    "    }\n",
    "\n",
    "X = X_trees.values\n",
    "y = y_trees.values\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print('[Fold %d/%d]' % (i + 1, kfold))\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    # Convert our data into XGBoost format\n",
    "    d_train = xgb.DMatrix(X_train, y_train)\n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "    d_test = xgb.DMatrix(test.values)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "    # Train the model! We pass in a max of 1,600 rounds (with early stopping after 70)\n",
    "    # and the custom metric (maximize=True tells xgb that higher metric is better)\n",
    "    mdl = xgb.train(params, d_train, 1600, watchlist, early_stopping_rounds=70, feval=gini_xgb, maximize=True, verbose_eval=100)\n",
    "\n",
    "    print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))\n",
    "    # Predict on our test data\n",
    "    p_test = mdl.predict(d_test, ntree_limit=mdl.best_ntree_limit)\n",
    "    sub['target'] += p_test/kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Instantiate Box-Cox Power Transformer\n",
    "# boxcox_transformer = PowerTransformer(method='box-cox')\n",
    "\n",
    "# Boxcox variables\n",
    "# pre_boxcox_vars = ['AirTemp']\n",
    "# boxcox_vars = ['boxcox_airtemp']\n",
    "\n",
    "# Fit-Trasform boxcox columns\n",
    "#df[pre_boxcox_vars] = log_current_speed.fit_transform(df[pre_boxcox_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Threshold probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-72333ec05a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msub_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msub_dt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'probas'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dt' is not defined"
     ]
    }
   ],
   "source": [
    "sub_dt = pd.DataFrame()\n",
    "\n",
    "sub_dt['probas'] = dt.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Get Predictions\n",
    "sub_dt.loc[sub_dt['probas'] < 0.8 , 'predict'] = 0 \n",
    "sub_dt.loc[sub_dt['probas'] >= 0.8 , 'predict'] = 1 \n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, sub_dt['predict'])\n",
    "print(\"Confusion Matrix: \\n\",conf_mat)\n",
    "\n",
    "# Compute classification report\n",
    "report = classification_report(y_test, sub_dt['predict'])\n",
    "print(\"Report: \\n\",report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True vs Pred \n",
    "real_vs_pred = y_val.copy().reset_index()[['Tacking']]\n",
    "#real_vs_pred['True Labels'] = y_val\n",
    "real_vs_pred['Predictions'] = sub_dt['predict']\n",
    "real_vs_pred.reset_index(inplace = True)\n",
    "real_vs_pred.head()\n",
    "\n",
    "\n",
    "# Checking True vs Predicted Labels\n",
    "real_vs_pred.plot(x='index', y='Tacking', kind = 'scatter', color = 'g', figsize = (7,7),label = 'best')\n",
    "plt.axis([0,100, 0, 1])\n",
    "real_vs_pred.plot(x='index', y='Predictions', kind = 'scatter', color = 'g', figsize = (7,7),label = 'best')\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.axis([0,100, 0, 1])\n",
    "# plt.ylim((0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost A) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'reg_lambda': 0.8,\n",
    "    'reg_alpha': 0.4,\n",
    "    'max_depth': 7,\n",
    "    'min_samples_leaf': 100,\n",
    "    'min_samples_split': 2,\n",
    "}\n",
    "clf = xgb.XGBClassifier(**xgb_params)\n",
    "clf.fit(X, np.ravel(y), eval_metric='auc', verbose=True)\n",
    "\n",
    "print(type(clf))\n",
    "print(clf.get_xgb_params())\n",
    "\n",
    "# Predict on unseen dataset\n",
    "y_xgb_pred = clf.predict(X)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_xg_pred)\n",
    "print(\"Confusion Matrix: \\n\",conf_mat)\n",
    "\n",
    "# Compute classification report\n",
    "report = classification_report(y_test, y_xg_pred)\n",
    "print(\"Report: \\n\",report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost B) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_trees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cc0acf500be2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Defining Training and Test Set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_trees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_trees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_trees' is not defined"
     ]
    }
   ],
   "source": [
    "# Defining Training and Test Set\n",
    "X = X_trees.values\n",
    "y = y_trees.values\n",
    "test = X_test\n",
    "\n",
    "# Defining submission object\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = X_test.index\n",
    "sub['target'] = np.zeros_like(X_test.index)\n",
    "\n",
    "# Instatiate StratifiedKFold object\n",
    "kfold = 5\n",
    "skf = StratifiedKFold(n_splits=kfold)\n",
    "\n",
    "# More parameters has to be tuned. Good luck :)\n",
    "params = {\n",
    "    # 'min_child_weight': 10.0,\n",
    "    'objective': 'binary:logistic', # Gives probability of belonging to a class\n",
    "    'eval_metric': 'auc',\n",
    "    'max_depth': 7,\n",
    "    'max_delta_step': 1.8,\n",
    "    'colsample_bytree': 1,\n",
    "    'subsample': 1,\n",
    "    'eta': 0.02,\n",
    "    'gamma': 0,\n",
    "    'class_weight': 'balanced'\n",
    "    # 'num_boost_round' : 700\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining gini metric\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return 'gini', gini_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-84bdd6397572>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_kf_xgb_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Train XGBoost with Stratified-KFolds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[Fold %d/%d]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "def build_kf_xgb_model(X = X, y = y, test = test, params = params ):\n",
    "    # Train XGBoost with Stratified-KFolds\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        print('[Fold %d/%d]' % (i + 1, kfold))\n",
    "        X_train, X_valid = X[train_index], X[test_index]\n",
    "        y_train, y_valid = y[train_index], y[test_index]\n",
    "        # Convert our data into XGBoost format\n",
    "        d_train = xgb.DMatrix(X_train, y_train)\n",
    "        d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "        d_test = xgb.DMatrix(test.values)\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "        # Train the model! We pass in a max of 1,600 rounds (with early stopping after 70)\n",
    "        # and the custom metric (maximize=True tells xgb that higher metric is better)\n",
    "        mdl = xgb.train(params, d_train, 1600, watchlist, early_stopping_rounds=70, feval=gini_xgb, maximize=True, verbose_eval=100)\n",
    "\n",
    "        print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))\n",
    "        # Predict on our test data\n",
    "        p_test = mdl.predict(d_test, ntree_limit=mdl.best_ntree_limit)\n",
    "        sub['target'] += p_test/kfold\n",
    "        return sub\n",
    "    \n",
    "# sub = build_kf_xgb_model(X, y, test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    # Get Predictions\n",
    "    sub.loc[sub['target'] < 0.5 , 'predict'] = 0 \n",
    "    sub.loc[sub['target'] >= 0.5 , 'predict'] = 1 \n",
    "    sub.target.min()\n",
    "\n",
    "    # Predict on unseen dataset\n",
    "    y_xg_pred = sub['predict']\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_mat = confusion_matrix(y_test, y_xg_pred)\n",
    "    print(\"Confusion Matrix: \\n\",conf_mat)\n",
    "\n",
    "    # Compute classification report\n",
    "    report = classification_report(y_test, y_xg_pred)\n",
    "    print(\"Report: \\n\",report)\n",
    "    \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a23d26aba8c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instantiate LogisticRegression classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit the LR classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dbc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dbc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiate LogisticRegression classifier\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit the LR classifier\n",
    "lr.fit(X_dbc, y_dbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5c7b95d8087d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict on unseen dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Compute confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict on unseen dataset\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Confusion Matrix: \\n\",conf_mat)\n",
    "\n",
    "# Compute classification report\n",
    "report = classification_report(y_test, y_pred_lr)\n",
    "print(\"Report: \\n\",report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate linear SVM classifier\n",
    "lsvm = LinearSVC(max_iter = 10000)\n",
    "\n",
    "# Fit the SVM classifier\n",
    "lsvm.fit(X_dbc, y_dbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on unseen dataset\n",
    "y_pred_lsvm = lsvm.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred_lsvm)\n",
    "print(\"Confusion Matrix: \\n\",conf_mat)\n",
    "\n",
    "# Compute classification report\n",
    "report = classification_report(y_test, y_pred_lsvm)\n",
    "print(\"Report: \\n\",report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-521ab0f768f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instantiate SVM classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit the SVM classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dbc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dbc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiate SVM classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Fit the SVM classifier\n",
    "svm.fit(X_dbc, y_dbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on unseen dataset\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred_svm)\n",
    "print(\"Confusion Matrix: \\n\",conf_mat)\n",
    "\n",
    "# Compute classification report\n",
    "report = classification_report(y_test, y_pred_svm)\n",
    "print(\"Report: \\n\",report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SVM classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 100)\n",
    "\n",
    "# Fit the SVM classifier\n",
    "knn.fit(X_dbc, y_dbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-92c4d91b8457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict on unseen dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Compute confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'knn' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict on unseen dataset\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"Confusion Matrix: \\n\",conf_mat)\n",
    "\n",
    "# Compute classification report\n",
    "report = classification_report(y_test, y_pred_knn)\n",
    "print(\"Report: \\n\",report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Time Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a895559fbab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reshaping Training and Test as input for LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;31m# Intervals of 160 s = 2.67 min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX_train_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX_test_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Reshaping Training and Test as input for LSTM \n",
    "time_steps = 10*2*2*2*2 # Intervals of 160 s = 2.67 min\n",
    "X_train= X_train_df.values.reshape((-1, time_steps, X_train_df.shape[1]))\n",
    "y_train = y_train_df.values.reshape(-1, 1)\n",
    "X_test= X_test_df.values.reshape(-1, time_steps, X_train_df.shape[1])\n",
    "y_test = y_test_df.values.reshape(-1,time_steps)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removed Feature Selection Cell from LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-80b8fc4c4dd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read SEEN data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/seen_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DateTime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DateTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create a list of column names to drop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Read SEEN data\n",
    "df = pd.read_csv('./data/seen_data.csv',header = 0)\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "\n",
    "# Create a list of column names to drop\n",
    "to_drop = [] + \\\n",
    "[] + \\\n",
    "[] + \\\n",
    "[] + \\\n",
    "[] + \\\n",
    "[] + \\\n",
    "[] + \\\n",
    "[] + \\\n",
    "[] + \\\n",
    "[] + \\\n",
    "[] + \\\n",
    "[]\n",
    "\n",
    "keep = ['TWS', 'AWS', 'WSoG'] + \\\n",
    "['SoS', 'AvgSoS', 'SoG','VMG'] + \\\n",
    "['AWA','TWA', 'TWD'] + \\\n",
    "['HoG', 'HeadingTrue' ,'HeadingMag', 'Yaw'] + \\\n",
    "['CurrentDir', 'CurrentSpeed'] + \\\n",
    "['Roll','Pitch'] + \\\n",
    "['RudderAng', 'Leeway'] + \\\n",
    "['VoltageDrawn'] + \\\n",
    "['Longitude', 'Latitude'] + \\\n",
    "['AirTemp'] + \\\n",
    "['DateTime'] + \\\n",
    "['ModePilote']\n",
    "\n",
    "# Assert Number of Variables\n",
    "assert len(to_drop) + len(keep) == 26\n",
    "\n",
    "# Drop those columns from the dataset\n",
    "df = df.drop(to_drop, axis=1)\n",
    "\n",
    "#############################################################################\n",
    "# selection = ['DateTime', 'CurrentSpeed', 'CurrentDir', 'TWA', 'AWS', 'AWA',\n",
    "#       'Roll', 'Pitch', 'HeadingMag', 'HoG', 'HeadingTrue', 'AirTemp',\n",
    "#       'Longitude', 'Latitude', 'SoS', 'AvgSoS', 'VMG', 'RudderAng',\n",
    "#       'Leeway', 'TWD', 'WSoG', 'VoltageDrawn', 'ModePilote']\n",
    "# df = df.drop(selection, axis=1)\n",
    "\n",
    "# Print remaning columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
